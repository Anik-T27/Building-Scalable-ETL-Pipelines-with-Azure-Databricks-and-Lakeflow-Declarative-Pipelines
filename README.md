# Building-Scalable-ETL-Pipelines-with-Azure-Databricks-and-Lakeflow-Declarative-Pipelines

## ğŸ“Œ Overview  
This project implements an **end-to-end data engineering pipeline** for aviation datasets (airports, flights, passengers, bookings) using the **Databricks Lakehouse Platform**.  
It follows the **Medallion Architecture (Bronze â†’ Silver â†’ Gold)** with **Autoloader, Delta Live Tables (DLT), PySpark, SQL**, and supports **incremental loads, schema evolution, CDC, and SCD**.  
Deployed on **Databricks Serverless Compute**, it delivers **analytics-ready models** enabling insights into bookings, flights, passengers, and airport performance.  

---

## ğŸ“‚ Repository Structure  

```
Building-Scalable-ETL-Pipeline-with-Azure-Databricks-and-Lakeflow-Declarative-Pipelines/
â”‚
â”œâ”€â”€ ğŸ“Š Datasets/                # Aviation datasets (CSV/XLS files)
â”‚   â”œâ”€â”€ dim_airports.csv
â”‚   â”œâ”€â”€ dim_airports_increment.csv
â”‚   â”œâ”€â”€ dim_airports_scd.csv
â”‚   â”œâ”€â”€ dim_flights.csv
â”‚   â”œâ”€â”€ dim_flights_increment.csv
â”‚   â”œâ”€â”€ dim_flights_scd.csv
â”‚   â”œâ”€â”€ dim_passengers.csv
â”‚   â”œâ”€â”€ dim_passengers_increment.csv
â”‚   â”œâ”€â”€ dim_passengers_scd.csv
â”‚   â”œâ”€â”€ fact_bookings.csv
â”‚   â””â”€â”€ fact_bookings_increment.csv
â”‚
â”œâ”€â”€ ğŸ“œ Docx/                    # Project documentation and diagrams
â”‚   â””â”€â”€ Project Architecture.png
â”‚
â”œâ”€â”€ ğŸ Scripts/                 # Python scripts for ingestion, DLT, and transformations
â”‚   â”œâ”€â”€ bronze_layer.py
â”‚   â”œâ”€â”€ dlt_pipeline.py
â”‚   â”œâ”€â”€ gold_dims.py
â”‚   â”œâ”€â”€ setup.py
â”‚   â””â”€â”€ src_parameters.py
â”‚
â”œâ”€â”€ ğŸ“‘ ProjectReport/           # Final report (Word document)
â”‚   â””â”€â”€ report_project2.docx
â”‚
â””â”€â”€ ğŸ“˜ README.md                # Project overview

```

## âš™ï¸ Tech Stack  
- **Databricks Lakehouse (Serverless Compute)**  
- **Delta Lake**  
- **Autoloader** (incremental ingestion, schema evolution)  
- **Delta Live Tables (DLT)** (transformations, CDC handling, quality checks)  
- **PySpark & SQL** (star schema modeling, SCD, fact/dim tables)

## ğŸš€ Features  
- Incremental data ingestion with **Autoloader**  
- Schema inference and evolution  
- **CDC and SCD** logic for maintaining up-to-date records  
- Data quality enforcement using DLT expectations  
- Analytics-ready **Star Schema** (fact_bookings with dimension tables)  
- Scalable execution using **Serverless Compute**

